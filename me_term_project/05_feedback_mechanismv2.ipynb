{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "class NoveltyDetectionSystem:\n",
    "    def __init__(self, pca_path, kmeans_path, encoder_path):\n",
    "        \"\"\"Initialize the system with pre-trained PCA, KMeans, and Label Encoder.\"\"\"\n",
    "        with open(pca_path, 'rb') as f:\n",
    "            self.pca = pickle.load(f)\n",
    "        with open(kmeans_path, 'rb') as f:\n",
    "            self.kmeans = pickle.load(f)\n",
    "        with open(encoder_path, 'rb') as f:\n",
    "            self.label_encoder = pickle.load(f)\n",
    "\n",
    "        self.n_clusters = self.kmeans.n_clusters\n",
    "\n",
    "    def extract_features(self, image_paths):\n",
    "        \"\"\"Extract VGG16 fc1 features from a batch of preprocessed images.\"\"\"\n",
    "        from tensorflow.keras.applications.vgg16 import VGG16\n",
    "        model = VGG16(weights='imagenet', include_top=True)\n",
    "        feature_extractor = Model(inputs=model.input, \n",
    "                                  outputs=model.get_layer('fc1').output)\n",
    "        \n",
    "        features = []\n",
    "        for img_path in image_paths:\n",
    "            img = load_img(img_path, target_size=(224, 224))\n",
    "            img_array = img_to_array(img)\n",
    "            img_array = preprocess_input(img_array)\n",
    "            features.append(feature_extractor.predict(np.expand_dims(img_array, axis=0)).flatten())\n",
    "        \n",
    "        return np.array(features)\n",
    "\n",
    "    def process_batch(self, batch_features):\n",
    "        \"\"\"Process a batch of images and detect novelty.\"\"\"\n",
    "        # Step 1: Transform features using PCA\n",
    "        transformed_features = self.pca.transform(batch_features)\n",
    "\n",
    "        # Step 2: Compute distances to existing clusters\n",
    "        distances = self.kmeans.transform(transformed_features)\n",
    "        min_distances = np.min(distances, axis=1)\n",
    "\n",
    "        # Step 3: Detect novelty using a threshold\n",
    "        threshold = np.quantile(min_distances, 0.95)\n",
    "        novelty_mask = min_distances > threshold\n",
    "        novel_features = batch_features[novelty_mask]\n",
    "\n",
    "        if len(novel_features) > 0:\n",
    "            print(f\"Detected {len(novel_features)} novel samples.\")\n",
    "\n",
    "            # Step 4: Handle novel samples\n",
    "            self._create_new_cluster(novel_features)\n",
    "            self._update_system(batch_features)\n",
    "        else:\n",
    "            print(\"No novel samples detected.\")\n",
    "\n",
    "    def _create_new_cluster(self, novel_features):\n",
    "        \"\"\"Cluster novel samples and create new clusters.\"\"\"\n",
    "        dbscan = DBSCAN(eps=0.5, min_samples=2)\n",
    "        transformed = self.pca.transform(novel_features)\n",
    "        labels = dbscan.fit_predict(transformed)\n",
    "\n",
    "        n_new_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "        self.n_clusters += n_new_clusters\n",
    "        print(f\"Created {n_new_clusters} new cluster(s). Total clusters: {self.n_clusters}\")\n",
    "\n",
    "    def _update_system(self, batch_features):\n",
    "        \"\"\"Update PCA and KMeans with the expanded dataset.\"\"\"\n",
    "        # Combine existing and batch features\n",
    "        combined_features = np.vstack([self.pca.inverse_transform(self.kmeans.cluster_centers_), batch_features])\n",
    "\n",
    "        # Retrain PCA\n",
    "        self.pca = PCA(n_components=50)\n",
    "        combined_transformed = self.pca.fit_transform(combined_features)\n",
    "\n",
    "        # Retrain KMeans\n",
    "        self.kmeans = KMeans(n_clusters=self.n_clusters, n_init=10)\n",
    "        self.kmeans.fit(combined_transformed)\n",
    "\n",
    "    def visualize_clusters(self):\n",
    "        \"\"\"Visualize clusters using t-SNE.\"\"\"\n",
    "        all_features = self.pca.inverse_transform(self.kmeans.cluster_centers_)\n",
    "        tsne = TSNE(n_components=2, random_state=0)\n",
    "        reduced = tsne.fit_transform(all_features)\n",
    "\n",
    "        plt.scatter(reduced[:, 0], reduced[:, 1], c=np.arange(self.n_clusters))\n",
    "        plt.title(f\"Cluster Visualization ({self.n_clusters} Clusters)\")\n",
    "        plt.xlabel(\"t-SNE Dim 1\")\n",
    "        plt.ylabel(\"t-SNE Dim 2\")\n",
    "        plt.colorbar(label=\"Cluster ID\")\n",
    "        plt.show()\n",
    "\n",
    "# Usage\n",
    "# Paths to pre-trained models\n",
    "pca_path = \"../models/pca.pickle\"\n",
    "kmeans_path = \"../models/kmeans.pickle\"\n",
    "encoder_path = \"../models/label_encoder.pickle\"\n",
    "\n",
    "# Initialize the system\n",
    "system = NoveltyDetectionSystem(pca_path, kmeans_path, encoder_path)\n",
    "\n",
    "# Load the batch of images\n",
    "batch_dir = Path(\"NEU_mixed_batch_40\")\n",
    "batch_images = sorted(batch_dir.glob(\"*.bmp\"))  # Adjust extension if needed\n",
    "batch_features = system.extract_features(batch_images)\n",
    "\n",
    "# Process the batch\n",
    "system.process_batch(batch_features)\n",
    "\n",
    "# Visualize the clusters\n",
    "system.visualize_clusters()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
