{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. System Initialization\n",
    "\n",
    "Live feedback system for defect classification with dynamic cluster adaptation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import gridspec\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "import skimage.io\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0,'../')\n",
    "from helper import classification_tools as ct\n",
    "from helper import visualize as vis\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fc1 features saved from the previous step\n",
    "fc1_path = Path('..','data','features','VGG16_fc1_features_std.pickle')\n",
    "assert fc1_path.is_file()\n",
    "\n",
    "# label encoder model which converts string labels to integers.\n",
    "le_path = Path('..','models','label_encoder.pickle')\n",
    "assert le_path.is_file()\n",
    "\n",
    "# load the data and label encoder into memory\n",
    "with open(fc1_path, 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "with open(le_path, 'rb') as f:\n",
    "    le = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = data['filename']  # file paths to each image\n",
    "fc1 = data['features']  # array containing fc1 features for each file\n",
    "labels = data['labels']  # string labels for each image\n",
    "y_gt = le.transform(labels)  # integer labels for each image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feedback System Implementation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from predictive_model import le # Import label encoder\n",
    "\n",
    "class FeedbackSystem:\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        self.pca = None\n",
    "        self.new_data = []\n",
    "        self.new_labels = []\n",
    "        self.n_clusters = 7  # Initial cluster count\n",
    "        self.load_initial_model()\n",
    "\n",
    "    def load_initial_model(self):\n",
    "        \"\"\"Load pre-trained models with fixed PCA components\"\"\"\n",
    "        self.pca = PCA(n_components=50, whiten=True, svd_solver='full')\n",
    "        self.pca.fit(fc1)  # Fit on initial dataset\n",
    "        \n",
    "        # Initial clustering\n",
    "        self.model = KMeans(n_clusters=self.n_clusters, init='k-means++', n_init=10)\n",
    "        self.model.fit(self.pca.transform(fc1))\n",
    "\n",
    "    def process_feedback(self, features):\n",
    "        \"\"\"Process user feedback for a single image\"\"\"\n",
    "        reduced = self.pca.transform([features])\n",
    "        cluster = self.model.predict(reduced)[0]\n",
    "        predicted_label = le.inverse_transform([cluster])[0]\n",
    "\n",
    "        is_correct = input(f\"Predicted: {predicted_label}. Correct? (y/n): \").lower() == 'y'\n",
    "        \n",
    "        if not is_correct:\n",
    "            is_new_class = input(\"New class? (y/n): \").lower() == 'y'\n",
    "            if is_new_class:\n",
    "                new_class = input(\"Class name: \").strip()\n",
    "                if new_class not in le.classes_:\n",
    "                    le.classes_ = np.append(le.classes_, new_class)\n",
    "                    self.n_clusters += 1\n",
    "                    print(f\"Added '{new_class}'. Total clusters: {self.n_clusters}\")\n",
    "                else:\n",
    "                    print(\"Class exists. Using existing label.\")\n",
    "            else:\n",
    "                new_class = input(\"Correct label: \").strip()\n",
    "                if new_class not in le.classes_:\n",
    "                    print(\"Error: Invalid label\")\n",
    "                    return\n",
    "\n",
    "            self.new_data.append(features)\n",
    "            self.new_labels.append(new_class)\n",
    "            print(\"Feedback stored. Retrain when ready.\")\n",
    "        else:\n",
    "            print(\"Correct prediction recorded.\")\n",
    "\n",
    "    def retrain_model(self):\n",
    "        \"\"\"Quick retrain using only new feedback data\"\"\"\n",
    "        if not self.new_data:\n",
    "            print(\"No new data to retrain\")\n",
    "            return\n",
    "\n",
    "        # Convert labels to integers\n",
    "        encoded_labels = le.transform(self.new_labels)\n",
    "        \n",
    "        # Apply PCA transform\n",
    "        transformed = self.pca.transform(self.new_data)\n",
    "        \n",
    "        # Retrain with updated cluster count\n",
    "        self.model = KMeans(\n",
    "            n_clusters=self.n_clusters,\n",
    "            init='k-means++',\n",
    "            n_init=10  # Reduced for faster training\n",
    "        )\n",
    "        self.model.fit(transformed)\n",
    "        \n",
    "        print(f\"Model retrained with {self.n_clusters} clusters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Extraction Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "def extract_features(img_path):\n",
    "    \"\"\"Feature extractor for live images\"\"\"\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = preprocess_input(img_array)\n",
    "    return img_array.flatten()  # Simplified for demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Demonstration Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize feedback system\n",
    "fb_system = FeedbackSystem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo sequence\n",
    "demo_images = [\n",
    "    (\"new_class_1.bmp\", True),\n",
    "    (\"new_class_2.bmp\", True),\n",
    "    (\"existing_class.bmp\", False)\n",
    "]\n",
    "\n",
    "for img_path, is_new in demo_images:\n",
    "    features = extract_features(img_path)\n",
    "    fb_system.process_feedback(features)\n",
    "    \n",
    "    if is_new:\n",
    "        fb_system.retrain_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualization (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optional: Add visualization code from 03_standard.ipynb here\n",
    "\n",
    "Include t-SNE plots or confusion matrices if time permits"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
