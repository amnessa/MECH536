{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from predictive_model import le # Import label encoder\n",
    "\n",
    "class FeedbackSystem:\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        self.pca = None\n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "        self.load_initial_model()\n",
    "\n",
    "    def load_initial_model(self):\n",
    "        # Load pre-trained PCA and KMeans\n",
    "        with open('../data/features/VGG16_fcl_features_std.pickle', 'rb') as f:\n",
    "            features = pickle.load(f)['features']\n",
    "        self.pca = PCA(n_components=35, whiten=True, svd_solver='full')\n",
    "        self.pca.fit(features)  # Use loaded features instead of undefined 'fci'\n",
    "        self.model = KMeans(n_clusters=7, init='k-means++', n_init=500)\n",
    "        self.model.fit(self.pca.transform(features))  # Use the same features\n",
    "\n",
    "    def process_feedback(self, image_features):\n",
    "        # Predict\n",
    "        reduced_features = self.pca.transform([image_features])\n",
    "        cluster = self.model.predict(reduced_features)[0]\n",
    "        predicted_label = le.inverse_transform([cluster])[0]\n",
    "\n",
    "        # Get feedback\n",
    "        is_correct = input(f\"Predicted: {predicted_label}. Correct? (y/n): \").lower() == 'y'\n",
    "\n",
    "        if not is_correct:\n",
    "            is_new_class = input(\"Is this a new class? (y/n): \").lower() == 'y'\n",
    "            if is_new_class:\n",
    "                new_class = input(\"Enter class name: \")\n",
    "                if new_class not in le.classes_:\n",
    "                    le.classes_ = np.append(le.classes_, new_class)\n",
    "                    print(f\"New class '{new_class}' added.\")\n",
    "                else:\n",
    "                    print(\"Class already exists.\")\n",
    "            else:\n",
    "                correct_label = input(\"Enter correct label: \")\n",
    "                # Validate label exists\n",
    "                if correct_label not in le.classes_:\n",
    "                    print(\"Error: Label does not exist.\")\n",
    "                    return\n",
    "            # Store data for retraining\n",
    "            self.data.append(image_features)\n",
    "            self.labels.append(correct_label if not is_new_class else new_class)\n",
    "            print(\"Feedback stored. Retrain when ready.\")\n",
    "        else:\n",
    "            print(\"Feedback recorded. Thank you!\")\n",
    "        \n",
    "    def retrain_model(self):\n",
    "        if not self.data:\n",
    "            print(\"No new data to retrain.\")\n",
    "            return\n",
    "        # Encode labels\n",
    "        encoded_labels = le.transform(self.labels)\n",
    "        # Transform all data\n",
    "        updated_features = self.pca.transform(self.data)\n",
    "        # Retrain KMeans\n",
    "        self.model = KMeans(\n",
    "            n_clusters=len(le.classes_), \n",
    "            init='k-means++', \n",
    "            n_init=100\n",
    "        )\n",
    "        self.model.fit(updated_features)\n",
    "        # Reset stored data\n",
    "        self.data, self.labels = [], []\n",
    "        print(\"Model retrained with new data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16_path = Path('..','models','VGG16.h5')\n",
    "if not vgg16_path.is_file():\n",
    "    vgg16 = keras.applications.VGG16(include_top=True,  # include fully connected layers\n",
    "                                     weights='imagenet') # use pre-trained model\n",
    "    vgg16.save(vgg16_path) # save model so we don't have to download it everytime\n",
    "    \n",
    "else:   \n",
    "    vgg16 = keras.models.load_model(vgg16_path) # use saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer_extractor(model=vgg16, layer='fc1'):\n",
    "    \"\"\"\n",
    "    returns a model that will extract the outputs of *layer* from *model*.\n",
    "    \n",
    "    Parameters\n",
    "    -------------\n",
    "    model: keras model\n",
    "        full model from which intermediate layer will be extracted\n",
    "    layer: string\n",
    "        name of layer from which to extract outputs\n",
    "    \n",
    "    Returns\n",
    "    -------------\n",
    "    new_model: keras model\n",
    "        feature extractor model which takes the same inputs as *model* and returns the outputs\n",
    "        of the intermediate layer specified by *layer* by calling new_model.predict(inputs)\n",
    "    \"\"\"\n",
    "    assert layer in [x.name for x in model.layers]  # make sure the layer exists\n",
    "\n",
    "    new_model = keras.Model(inputs = vgg16.input, outputs=[vgg16.get_layer(layer).output])\n",
    "    \n",
    "    return new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc1_extractor = layer_extractor()\n",
    "fc1 = fc1_extractor.predict(images, verbose=True)\n",
    "\n",
    "# save results\n",
    "results = {'filename' : files,\n",
    "           'features': fc1,\n",
    "          'labels': labels,\n",
    "           'layer_name': 'fc1'\n",
    "          }\n",
    "\n",
    "feature_dir = Path('..','data','features')\n",
    "os.makedirs(feature_dir, exist_ok=True)\n",
    "with open(feature_dir / 'VGG16_fc1_features_std.pickle', 'wb') as f:\n",
    "    pickle.dump(results, f)\n",
    "\n",
    "print(fc1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage in feedback loop:\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "def extract_features(image_path):\n",
    "    img = image.load_img(image_path, target_size=(224, 224))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = preprocess_input(img_array)\n",
    "    features = fcl_extractor.predict(np.expand_dims(img_array, axis=0))\n",
    "    return features.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize system\n",
    "fb_system = FeedbackSystem()\n",
    "\n",
    "# For a new image:\n",
    "image_path = \"path/to/new_image.bmp\"\n",
    "features = extract_features(image_path)\n",
    "\n",
    "# Get prediction and feedback\n",
    "fb_system.process_feedback(features)\n",
    "\n",
    "# After collecting enough feedbacks:\n",
    "fb_system.retrain_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "fb_system = FeedbackSystem()\n",
    "new_image_features = [...]  # Extract features for a new image\n",
    "fb_system.process_feedback(new_image_features)\n",
    "# After collecting enough feedback data:\n",
    "# fb_system.retrain_model(new_data_list, new_label_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
