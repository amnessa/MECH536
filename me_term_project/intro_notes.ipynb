{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a project idea that integrates **three** of the required elements—**(1) ANNs**, **(2) data clustering**, and **(3) image processing**—and focuses on **novelty (anomaly) detection** in a robotics/manufacturing scenario, which should resonate well with your **robotics** and **materials science** background.\n",
    "\n",
    "---\n",
    "\n",
    "## Overview of the Proposed Project\n",
    "\n",
    "### High-Level Scenario\n",
    "\n",
    "1. You have a (simulated or real) **robotic inspection system** that checks surfaces or objects (e.g., manufactured parts, nanomaterial samples, or composite materials).\n",
    "2. A **camera** attached to the robot captures images of these parts.\n",
    "3. You apply **image processing** techniques (e.g., morphological operations, filtering) to enhance or extract relevant surface features (scratches, cracks, discolorations, anomalies).\n",
    "4. These processed images are then passed to a **Deep Neural Network** (e.g., a CNN or autoencoder) to learn a **feature representation**.\n",
    "5. On top of the learned feature space, you perform **data clustering** (e.g., k-means or hierarchical clustering) to:\n",
    "   - Group images (or patches) that are “similar” in terms of features,\n",
    "   - Identify clusters that do not match any known pattern (“novelty” or “anomaly”).\n",
    "\n",
    "The system thus **detects novel defects** or unknown categories of anomalies without requiring them to be explicitly labeled in advance, fulfilling the “discovery”/“decision making” part of the requirement.\n",
    "\n",
    "---\n",
    "\n",
    "## Why This Meets the Requirements\n",
    "\n",
    "1. **Use of ANN**: \n",
    "   - A Convolutional Neural Network (CNN) or an autoencoder-based approach will be used to extract high-level features from the images.  \n",
    "   - Alternatively, you can use a **CNN for known/normal classes** of defects vs. good parts (partial supervision), but crucially, you also allow the system to discover new anomaly types.\n",
    "\n",
    "2. **Data Clustering / Graph Theory**:\n",
    "   - After obtaining feature vectors from the ANN, you can cluster (using **k-means**, **DBSCAN**, or **graph-based clustering**) to discover new or unexpected clusters. \n",
    "   - Clusters that do not match “normal” data distributions are flagged as novel anomalies.\n",
    "\n",
    "3. **Image Processing**:\n",
    "   - You’ll apply **morphological operations** (e.g., dilation, erosion, opening, closing) or advanced filters (e.g., Gaussian filters, edge detection filters) to clean up noise, highlight specific shapes or cracks, etc.\n",
    "   - This step is especially relevant in materials/defects inspection, where small cracks or voids can be enhanced via morphological filters.\n",
    "\n",
    "4. **Not Just Another Supervised Training**:\n",
    "   - You may train a CNN or autoencoder on **normal** data (and maybe on some limited known anomalies). However, your overall pipeline goes beyond simple supervised classification:  \n",
    "     - The system is expected to **detect “novel” anomalies** (things it has never been trained on), by monitoring reconstruction error (in case of autoencoder) or by identifying out-of-distribution clusters (in case of CNN+clustering).  \n",
    "     - This answers the requirement to “form new categories based on them not being normal.”\n",
    "\n",
    "5. **Novelty Detection / Discovery**:\n",
    "   - You fulfill the “discovery” part by letting the clustering step form new classes or clusters that deviate from the normal feature representation.\n",
    "\n",
    "6. **Decision Making**:\n",
    "   - The robot (or software agent) can be programmed to respond to anomalies—e.g., “Alert the operator,” “Mark part as defective,” “Request further inspection.”  \n",
    "\n",
    "---\n",
    "\n",
    "## Step-by-Step Project Outline\n",
    "\n",
    "### 1. Data Collection (or Dataset Selection)\n",
    "- **Real or simulated** images of surfaces/parts with known conditions:  \n",
    "  - Normal samples (no defect).  \n",
    "  - Several known types of defects (scratches, cracks, discolorations, etc.).  \n",
    "  - Possibly unlabeled or partially labeled images where you suspect new anomalies might show up.  \n",
    "\n",
    "> If you don’t have a real-world dataset, you can generate synthetic data that mimics defects (using image processing scripts).\n",
    "\n",
    "### 2. Image Preprocessing & Feature Extraction\n",
    "1. **Morphological operations**  \n",
    "   - Use morphological filters (e.g., opening or closing) to reduce noise or isolate certain shapes (like cracks).  \n",
    "   - You can also apply advanced filtering (e.g., Gabor filters, wavelet transforms) if relevant to highlight texture or microstructure patterns in materials.\n",
    "\n",
    "2. **Deep Feature Extraction**  \n",
    "   - You can build a **CNN** for feature extraction, possibly pretrained on a large dataset (like ImageNet) and fine-tuned on your domain data.  \n",
    "   - Alternatively, use a **convolutional autoencoder**:  \n",
    "     - Train it to reconstruct normal parts/surfaces.  \n",
    "     - The latent space (bottleneck features) is then used for clustering.  \n",
    "     - Reconstruction error can be used as an anomaly score.\n",
    "\n",
    "### 3. Clustering / Novelty Detection\n",
    "1. **Dimensionality Reduction (Optional)**  \n",
    "   - If the latent feature vectors are still large, use **PCA** to reduce dimensionality before clustering.\n",
    "\n",
    "2. **Clustering**  \n",
    "   - Run **k-means** (or DBSCAN / hierarchical clustering) on the resulting feature vectors.  \n",
    "   - Identify clusters corresponding to known patterns (e.g., normal, known defect types).  \n",
    "   - If a cluster (or data points) do not fit well into any existing cluster, label them as **potentially novel**.\n",
    "\n",
    "3. **Novelty Classification**  \n",
    "   - A simple approach is: any data point that has a **high distance to all known cluster centroids** is flagged as novel.  \n",
    "   - Alternatively, for autoencoders: a **high reconstruction error** suggests the object does not belong to the learned normal distribution => anomaly.\n",
    "\n",
    "### 4. Automated Decision / Robot Action\n",
    "- Once you flag an anomaly, the system can:\n",
    "  - **Alert** an operator to inspect the part.  \n",
    "  - Move the robotic arm to remove or isolate the defective part.  \n",
    "  - Log the new anomaly so that it can be labeled and (optionally) used to update the model for future runs.\n",
    "\n",
    "### 5. Evaluation & Results\n",
    "- Demonstrate with a test dataset that includes:\n",
    "  - Normal samples,\n",
    "  - Known anomaly types,\n",
    "  - *Potentially new* anomaly type (simulate or introduce a truly novel defect).  \n",
    "- Show how the system successfully recognizes known defects (via the recognized clusters) and flags the new unknown defect as novel.\n",
    "\n",
    "### 6. Live Demo\n",
    "- A short live or recorded demonstration:\n",
    "  - Show the input images (or real-time camera feed).  \n",
    "  - Visualize the morphological-processing steps.  \n",
    "  - Show how the neural network or autoencoder extracts features.  \n",
    "  - Run clustering; highlight clusters.  \n",
    "  - Mark anomalies in red or produce a textual/log-based warning.\n",
    "\n",
    "---\n",
    "\n",
    "## Technical Details to Highlight During Presentation\n",
    "\n",
    "1. **CNN/Autoencoder Architecture**  \n",
    "   - Outline the layers of your chosen architecture (convolution, pooling, fully connected, etc.).  \n",
    "   - Indicate if you use a pretrained backbone or train from scratch.\n",
    "\n",
    "2. **Data Processing Pipeline**  \n",
    "   - Summarize the morphological filters you used and why (e.g., “We used dilation to fill small holes, then used an edge detector to highlight cracks.”).\n",
    "\n",
    "3. **Clustering Method**  \n",
    "   - Explain **why** you chose k-means vs. DBSCAN vs. another approach.  \n",
    "   - Possibly show the inertia (k-means) or silhouette plots to pick the number of clusters.\n",
    "\n",
    "4. **Novelty Detection Criterion**  \n",
    "   - If using an autoencoder: highlight how reconstruction error correlates with anomalies.  \n",
    "   - If using clustering: highlight distance thresholds (e.g., “Any point whose distance to its nearest centroid is > X is flagged as novel.”).  \n",
    "\n",
    "5. **Performance Metrics**  \n",
    "   - Accuracy in classifying known defects,  \n",
    "   - False positives/negatives for anomaly detection,  \n",
    "   - Possibly F1 scores for the novelty detection if you have ground truth.  \n",
    "\n",
    "6. **Potential Improvements**  \n",
    "   - Training on more diverse data,  \n",
    "   - Improving the neural net architecture,  \n",
    "   - Real-time integration in a robotic system,  \n",
    "   - On-the-fly updating of the clusters when new anomalies are confirmed.\n",
    "\n",
    "---\n",
    "\n",
    "## Example Use Cases / Extensions\n",
    "\n",
    "- **Materials Inspection**: Detecting new types of micro-cracks in thin films or coatings.  \n",
    "- **Manufacturing Quality Control**: Flagging unusual defects during an assembly-line process.  \n",
    "- **Warehouse Robots**: Spotting deformed or mislabeled items among normal ones.  \n",
    "\n",
    "---\n",
    "\n",
    "## Why It’s a Solid Graduate-Level Project\n",
    "\n",
    "1. It **integrates multiple ML/vision components** (image processing, ANN feature extraction, clustering for novelty).  \n",
    "2. It **goes beyond simple classification** by detecting and categorizing truly new anomalies.  \n",
    "3. It **aligns with robotics tasks**, where discovering unexpected situations is crucial.  \n",
    "4. It leverages your **materials science/nanotechnology background**, letting you focus on realistic defect inspection scenarios.\n",
    "\n",
    "---\n",
    "\n",
    "### Final Check Against Requirements\n",
    "\n",
    "- **At least 3 methods used**: \n",
    "  1. **ANN** (CNN or autoencoder), \n",
    "  2. **Data clustering** (k-means/DBSCAN), \n",
    "  3. **Image processing** (morphological ops, filters).\n",
    "- **Discovery of something novel**: The pipeline identifies new anomalies/clusters that are distinct from known categories.\n",
    "- **Not purely supervised**: You can have a small supervised component (learning “normal” or “common defects”), but the real emphasis is on clustering & novelty detection—satisfying the requirement that the system forms new categories.\n",
    "- **Robotic agent**: The system can be portrayed as an inspection robot deciding how to handle anomalies (eat the candy, throw it, pass it along—metaphorically speaking).\n",
    "\n",
    "---\n",
    "\n",
    "## Concluding Remarks\n",
    "\n",
    "This project fulfills the spirit of creating a **multifaceted, discovery-focused** system. You’ll demonstrate:\n",
    "1. A compelling **problem setup** (robotic inspection of materials/parts).\n",
    "2. An **ML pipeline** that combines **image processing**, **deep feature extraction**, and **clustering** to detect novel defects.\n",
    "3. A clear demonstration of **decision-making** (flag or handle anomalies differently).  \n",
    "\n",
    "You can scale the complexity up or down depending on the time/resources you have. Even a **proof-of-concept** with a small synthetic dataset can illustrate the core ideas effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a streamlined approach for an **incremental novelty-detection** project that uses a simple **autoencoder** or **CNN** pipeline, integrates **image processing**, **clustering/novelty detection**, and **user feedback**. It’s designed to be relatively quick to implement (within ~4 days), even if this is your first deep-learning project, by leveraging **existing open-source code** and minimal custom modifications.\n",
    "\n",
    "---\n",
    "\n",
    "# 1. Project Concept in a Nutshell\n",
    "\n",
    "1. **Images as Input**  \n",
    "   - For simplicity, you can use a small, ready-made image dataset that resembles the “surface defect” or “object” scenario. Examples:  \n",
    "     - [**MVTec AD**](https://www.mvtec.com/company/research/datasets/mvtec-ad) (industrial surface anomaly dataset),  \n",
    "     - Or even a simpler dataset of random objects/defects from Kaggle.  \n",
    "   - Alternatively, you can generate synthetic “defect” images if you cannot find a suitable dataset.\n",
    "\n",
    "2. **Preprocessing / Morphological Ops**  \n",
    "   - Use **OpenCV** or similar libraries to do basic morphological transformations (e.g., dilation, erosion) to denoise or highlight shapes.  \n",
    "   - This satisfies the “image processing” requirement and can be done with just a few lines of code.\n",
    "\n",
    "3. **Neural Network for Feature Extraction**  \n",
    "   - Option A: **Autoencoder** trained **only on normal data**. Any new pattern with high reconstruction error is flagged as anomaly.  \n",
    "   - Option B: Use a **pretrained CNN** (e.g., ResNet, VGG) from `torchvision.models` or `tensorflow.keras.applications`, freeze it, and extract feature vectors. Then you do clustering or outlier detection on those features.\n",
    "\n",
    "4. **Clustering / Novelty Detection**  \n",
    "   - After extracting features, run **k-means** or **DBSCAN** to identify clusters. Anything that doesn’t fit well into existing clusters gets flagged as “novel.”\n",
    "   - This addresses the “data clustering” requirement.\n",
    "\n",
    "5. **User Feedback Loop**  \n",
    "   - When a new/novel cluster or anomaly is detected, you **prompt the user**: “Is this a new type of defect?”  \n",
    "   - If the user says **“Yes, it’s a new type”**, you store those images in a new class folder (or label them).  \n",
    "   - Then you can retrain or partially fine-tune the model (or re-run clustering) so that future occurrences of that defect are recognized in a known category.\n",
    "\n",
    "**Why This Is Achievable in 4 Days**  \n",
    "- You can rely heavily on existing GitHub code for **autoencoders**, **morphological operations** in OpenCV, **k-means** from scikit-learn, and a small script for user input.  \n",
    "- You only need to stitch these pieces together with minimal custom logic.\n",
    "\n",
    "---\n",
    "\n",
    "# 2. Quick-Start Implementation Steps\n",
    "\n",
    "Below is a pragmatic workflow to get a **minimum viable project** up and running quickly:\n",
    "\n",
    "## 2.1 Prepare or Download a Dataset\n",
    "\n",
    "1. **Choose a small dataset**:  \n",
    "   - For example, from the [**MVTec AD** dataset](https://www.mvtec.com/company/research/datasets/mvtec-ad), pick 1–2 object categories with normal and defective images.  \n",
    "   - Or a simpler, more generic dataset (e.g., images of “scratches” vs. “no scratches” from Kaggle).  \n",
    "2. **Organize** them into:  \n",
    "   - `train/normal/` (images with no defect)  \n",
    "   - `test/` (images with known or unknown defects + normal)\n",
    "\n",
    "## 2.2 Image Processing (Morphological Ops)\n",
    "\n",
    "1. **Install OpenCV** (`pip install opencv-python`).  \n",
    "2. For each image, apply a short pipeline, for example:\n",
    "   ```python\n",
    "   import cv2\n",
    "\n",
    "   # example morphological pipeline\n",
    "   img = cv2.imread('path/to/image', cv2.IMREAD_GRAYSCALE)\n",
    "   # 1) optional thresholding or blur\n",
    "   blurred = cv2.GaussianBlur(img, (3,3), 0)\n",
    "   # 2) morphological opening\n",
    "   kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3,3))\n",
    "   opened = cv2.morphologyEx(blurred, cv2.MORPH_OPEN, kernel)\n",
    "   # then feed `opened` image into your neural net\n",
    "   ```\n",
    "3. This step can be very minimal—just mention it in your presentation to fulfill the “image processing” requirement.\n",
    "\n",
    "## 2.3 Neural Network (Autoencoder or Pretrained CNN)\n",
    "\n",
    "### Option A: Autoencoder for Novelty Detection\n",
    "\n",
    "1. **Autoencoder Architecture**  \n",
    "   - A typical small convolutional autoencoder. Many GitHub examples exist—search “pytorch autoencoder anomaly detection” or “keras autoencoder anomaly detection.”  \n",
    "   - For instance, see [**pytorch-anomaly-detection**](https://github.com/hiram64/pytorch_anomaly_detection) or [**Keras Anomaly Detection**](https://github.com/curiousily/Anomaly-Detection-with-TensorFlow-2.0).  \n",
    "2. **Training**  \n",
    "   - Train **only** on the normal images for a few epochs until it reconstructs them decently.  \n",
    "   - Evaluate reconstruction error on your test set. If the error > threshold, label it as anomaly (novel).  \n",
    "3. **Integrate New Classes**  \n",
    "   - If you detect a new anomaly, ask the user: “Is this a truly new defect type?” If yes, you can store them in a `train/new_defect/` folder and **retrain** or partially fine-tune. \n",
    "   - Alternatively, keep it simpler and **just log** that the user says it’s new, so next time you see it, you continue to treat it as anomaly.  \n",
    "\n",
    "### Option B: Pretrained CNN + Clustering\n",
    "\n",
    "1. **Feature Extraction**  \n",
    "   - Import a pretrained model (e.g., ResNet18) in PyTorch or Keras.  \n",
    "   - **Freeze** its weights (no training needed, which is faster!).  \n",
    "   - Pass each image (possibly with morphological preprocessing) through the network, and **take the output** of a mid or penultimate layer as a feature vector.  \n",
    "2. **Clustering**  \n",
    "   - Collect all these feature vectors for your normal training set.  \n",
    "   - Run **k-means** (`sklearn.cluster.KMeans(n_clusters=1)` for the normal class, or more if you have multiple known classes).  \n",
    "   - Then, for new images, measure the distance to the cluster center(s). If the distance is too large → anomaly/novel.  \n",
    "3. **User Interaction**  \n",
    "   - If flagged as novel, ask the user if it’s a new type. If yes, update your clustering by telling k-means to add a new cluster (you can re-run k-means with `n_clusters = old + 1`).  \n",
    "\n",
    "**Which Option to Choose?**  \n",
    "- **Autoencoder** if you want a simpler “reconstruction error” approach.  \n",
    "- **Pretrained CNN** if you don’t want to train anything big and prefer quick feature extraction + clustering.\n",
    "\n",
    "---\n",
    "\n",
    "# 3. Adding User Feedback for New Categories\n",
    "\n",
    "A minimal approach to get user feedback in real-time:\n",
    "\n",
    "```python\n",
    "def user_confirmation(new_sample_image):\n",
    "    # Show image to user (matplotlib or OpenCV window)\n",
    "    cv2.imshow(\"Potential Novelty Detected\", new_sample_image)\n",
    "    cv2.waitKey(0)\n",
    "    # Ask user if it's a new type\n",
    "    response = input(\"Is this a new defect type? (y/n): \")\n",
    "    return response.lower() == 'y'\n",
    "```\n",
    "\n",
    "- If “y”, you store the image in a new folder or label set, and you can optionally re-run your cluster training or autoencoder training to incorporate this new class.\n",
    "\n",
    "---\n",
    "\n",
    "# 4. Existing Code References\n",
    "\n",
    "## Autoencoder-Based References\n",
    "1. **Keras**:  \n",
    "   - [François Chollet’s blog post on anomaly detection with autoencoders](https://blog.keras.io/building-autoencoders-in-keras.html)  \n",
    "   - GitHub examples: [**Keras Autoencoder**](https://github.com/curiousily/Anomaly-Detection-with-TensorFlow-2.0)  \n",
    "2. **PyTorch**:  \n",
    "   - [PyTorch Tutorial: Anomaly Detection with Autoencoders](https://medium.com/@hensaldi/autoencoder-anomaly-detection-in-pytorch-885024bc12d1)  \n",
    "   - [pytorch_anomaly_detection repo](https://github.com/hiram64/pytorch_anomaly_detection)\n",
    "\n",
    "## Pretrained CNN + Clustering\n",
    "1. **PyTorch**:\n",
    "   ```python\n",
    "   import torch\n",
    "   import torchvision.models as models\n",
    "   resnet = models.resnet18(pretrained=True)\n",
    "   for param in resnet.parameters():\n",
    "       param.requires_grad = False\n",
    "   # remove final layer or use an intermediate layer for features\n",
    "   ```\n",
    "   - Then do `k-means` from `sklearn.cluster`.\n",
    "2. **Keras**:\n",
    "   ```python\n",
    "   from tensorflow.keras.applications import ResNet50\n",
    "   base_model = ResNet50(weights='imagenet', include_top=False)\n",
    "   # Flatten output and cluster\n",
    "   ```\n",
    "   - See also [Keras + Clustering tutorial](https://androidkt.com/cluster-images-using-keras/).\n",
    "\n",
    "## Morphological Operations with OpenCV\n",
    "- Official docs: [OpenCV Python tutorials on morphological transformations](https://docs.opencv.org/4.x/d9/d61/tutorial_py_morphological_ops.html).  \n",
    "- Very straightforward to integrate.\n",
    "\n",
    "---\n",
    "\n",
    "# 5. Minimal Script Structure Example\n",
    "\n",
    "Below is an **outline** (pseudo-code) to show how to piece everything together quickly:\n",
    "\n",
    "```python\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# 1. Load or define a function to load images\n",
    "def load_images(folder):\n",
    "    images = []\n",
    "    for file in os.listdir(folder):\n",
    "        if file.endswith('.jpg') or file.endswith('.png'):\n",
    "            img = cv2.imread(os.path.join(folder, file), cv2.IMREAD_GRAYSCALE)\n",
    "            images.append(img)\n",
    "    return images\n",
    "\n",
    "# 2. Morphological processing\n",
    "def preprocess_image(img):\n",
    "    blur = cv2.GaussianBlur(img, (3,3), 0)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3,3))\n",
    "    opened = cv2.morphologyEx(blur, cv2.MORPH_OPEN, kernel)\n",
    "    return opened\n",
    "\n",
    "# 3. Feature extraction (pretrained CNN example with PyTorch)\n",
    "class FeatureExtractor(torch.nn.Module):\n",
    "    def __init__(self, original_model):\n",
    "        super(FeatureExtractor, self).__init__()\n",
    "        # remove the last layer of ResNet18 or keep up to avgpool\n",
    "        self.features = torch.nn.Sequential(*(list(original_model.children())[:-1]))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        return x.view(x.size(0), -1)\n",
    "\n",
    "resnet = models.resnet18(pretrained=True)\n",
    "for param in resnet.parameters():\n",
    "    param.requires_grad = False\n",
    "feature_extractor = FeatureExtractor(resnet)\n",
    "feature_extractor.eval()\n",
    "\n",
    "def get_feature_vector(img):\n",
    "    # convert to 3 channels, resize to 224x224 for ResNet\n",
    "    img_3ch = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "    img_resized = cv2.resize(img_3ch, (224, 224))\n",
    "    # normalize to [0,1], or use torchvision transforms\n",
    "    tensor = torch.tensor(img_resized, dtype=torch.float32).permute(2,0,1).unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        feat = feature_extractor(tensor)\n",
    "    return feat.numpy().flatten()\n",
    "\n",
    "# 4. Clustering on normal data\n",
    "normal_images = load_images('train/normal/')\n",
    "features = []\n",
    "for img in normal_images:\n",
    "    pre_img = preprocess_image(img)\n",
    "    fv = get_feature_vector(pre_img)\n",
    "    features.append(fv)\n",
    "features = np.array(features)\n",
    "\n",
    "kmeans = KMeans(n_clusters=1) # if only 1 normal cluster\n",
    "kmeans.fit(features)\n",
    "\n",
    "# 5. Novelty detection on test images\n",
    "test_images = load_images('test/')\n",
    "for img in test_images:\n",
    "    pre_img = preprocess_image(img)\n",
    "    fv = get_feature_vector(pre_img).reshape(1, -1)\n",
    "    dist = np.linalg.norm(kmeans.cluster_centers_ - fv, axis=1)[0]\n",
    "    \n",
    "    # If distance is above threshold => novel\n",
    "    threshold = 200.0  # pick a threshold by trial\n",
    "    if dist > threshold:\n",
    "        # Prompt user\n",
    "        cv2.imshow(\"Potential Novelty\", img)\n",
    "        cv2.waitKey(0)\n",
    "        resp = input(\"Is this a new type? y/n: \")\n",
    "        if resp.lower() == 'y':\n",
    "            # store or do something -> re-run KMeans with n_clusters+1, etc.\n",
    "            pass\n",
    "        else:\n",
    "            pass\n",
    "    else:\n",
    "        print(\"Looks normal.\")\n",
    "```\n",
    "\n",
    "This skeleton code:\n",
    "- Loads images,  \n",
    "- Applies morphological ops,  \n",
    "- Extracts features via a frozen ResNet,  \n",
    "- Clusters normal data with 1 cluster,  \n",
    "- Checks test images for distance to cluster center.  \n",
    "- Asks the user if new type or not.  \n",
    "\n",
    "You can refine it with your domain logic, better thresholds, more clusters if you have known classes, etc.\n",
    "\n",
    "---\n",
    "\n",
    "# 6. Tips to Fit in 4 Days\n",
    "\n",
    "1. **Keep It Small & Focused**: Use **a small subset** of images (10–50 normal, 10–20 anomalies). Enough to demonstrate the workflow without waiting for huge training times.  \n",
    "2. **Reuse Code**: Don’t write from scratch if you can avoid it—use tutorials and example repos.  \n",
    "3. **Minimal Tuning**: For your presentation, show that the concept works. Don’t worry too much about perfect accuracy. The main point is novelty detection + user feedback.  \n",
    "4. **Simple UI**: A command-line `input(\"Is this new? y/n\")` is enough. No need to build a fancy GUI.  \n",
    "5. **Presentation**: Emphasize that you used 3+ techniques (ANN, image processing, clustering) and you handle novelty detection with minimal user input.\n",
    "\n",
    "---\n",
    "\n",
    "# 7. Concluding Remarks\n",
    "\n",
    "- **Core Requirements**:  \n",
    "  1. **ANN**: Either an autoencoder or a pretrained CNN for feature extraction.  \n",
    "  2. **Image Processing**: Morphological ops in OpenCV.  \n",
    "  3. **Clustering**: K-means/DBSCAN for anomaly/novelty.  \n",
    "\n",
    "- **Non-Trivial Aspect**: Your system goes beyond pure supervised classification by detecting unknown anomalies, asking the user, and incrementally learning or logging new defect types.\n",
    "\n",
    "- **Deliverables**: In your ~10-minute presentation, show:  \n",
    "  1. The overall pipeline (data → morphological processing → neural net → clustering → detection).  \n",
    "  2. A short live/recorded demo with a couple test images that get flagged as novel.  \n",
    "  3. How user feedback can define new classes or confirm anomalies.\n",
    "\n",
    "This approach should be **feasible within ~4 days** if you focus on assembling existing snippets of code, do minimal parameter tuning, and keep the data size small. Good luck with your project!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
