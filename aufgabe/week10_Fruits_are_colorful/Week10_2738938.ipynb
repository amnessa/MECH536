{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vltmNTJUOO1A"
      },
      "source": [
        "# Full Name: Çağdaş Güven\n",
        "\n",
        "# Student ID: 2738938"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EX3aiSdnOII7"
      },
      "source": [
        "# Try to Tell Apples, Oranges and else apart\n",
        "\n",
        "Images for this assignment are provided at github and they will be automatically downloaded right after imports. When the files are unzip there should be a folder:  ```AppleOrange```.\n",
        "These are sample images, you can test with more if you want. While testing just for fun, I can try other stuff as well.\n",
        "\n",
        "Your objective is to convert <font color=\"magenta\"> **Apples to magenta** </font>, <font color=\"blue\"> **Oranges to Blue** </font> , end blur everything else! While changing color, try to keep the original shading (i.e. try not provide a flat single color if possible, keep the shadings to the best you can).  \n",
        "\n",
        "<font color=\"red\">Do not be **too picky** and lose too much time</font>. Variety of images are provided so that you get the idea that generalizable / perfect filters are not easy to build. Yet your function is expected to work on more than one image at an acceptable level.  \n",
        "\n",
        "By the same token, you can use the ```fakes```, also for for fun to see how your algorighm works on unrealted images, and why a general filter is not that easy...  \n",
        "\n",
        "At the end as usual you are expected to **clear all outputs** and then save this file as **Week10_student_id.ipynb** and upload to the assignment at [ODTU Class](https://odtuclass2024f.metu.edu.tr/mod/assign/view.php?id=100364).  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zLzqIVXJSCRU"
      },
      "source": [
        "# imports as usual\n",
        "You are only allowed to use concepts related to what we have seen in class and use only the following imports. You can import sub-libraries with new names etc. but NO NEW LIBRARIES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eQZIUC0gSQ7F"
      },
      "outputs": [],
      "source": [
        "# not that all of them are necessary, but you are not allowed to import any new library\n",
        "# yet as before, you can import sub libraries: i.e.:\n",
        "#       from skimage import measure\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as pimg # check this out this is new\n",
        "from numpy import cos, arccos, sin, pi, round\n",
        "from numpy.linalg import matrix_rank as rank\n",
        "from numpy.linalg import svd, eig\n",
        "from scipy.linalg import orth\n",
        "import cv2 as cv\n",
        "from PIL import Image # good old pillow\n",
        "import sklearn as skl # famous sci-kit learn\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import pairwise_distances_argmin\n",
        "from sklearn.utils import shuffle\n",
        "from skimage.exposure import histogram , exposure\n",
        "import skimage as ski # equally famous sci-kit image\n",
        "!rm bug_numpy_utils.py 2>/dev/null  # at the first run file does not exits but error should print\n",
        "!wget https://raw.githubusercontent.com/bugrakoku/bug_python_utils/main/bug_numpy_utils.py\n",
        "from bug_numpy_utils import MatPrint, CData, text2mat # note that once these files are downloaded you can read their content.\n",
        "!rm me536utils.py 2>/dev/null  # at the first run file does not exits but error should print\n",
        "!wget https://raw.githubusercontent.com/bugrakoku/bug_python_utils/main/me536utils.py\n",
        "from me536utils import RotMat"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1-LOxSkVzxH"
      },
      "source": [
        "## get images\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "35qHlbaGV47L"
      },
      "outputs": [],
      "source": [
        "# !rm AppleOrange.zip 2>/dev/null # just in case\n",
        "# !wget https://github.com/bugrakoku/data4all/raw/main/AppleOrange.zip # get the zip file\n",
        "# !unzip AppleOrange.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jREEYYBZS4vQ"
      },
      "source": [
        "# Get prepared\n",
        "Below you can check images, perform tests runs, find critical color values etc.  \n",
        "Leave all your preparation code so that I can see how you have reached the final implementation of the function. This part I will NOT run for evaluation! I will only run the ```AorO()``` and ```AorO2()``` functions in my tests!  \n",
        "\n",
        "You can add as many code and text cells as you like below. But at the end, as I said above, I will just call the ```AorO()``` or ```AorO2()``` function.  \n",
        "And please **DO CLEAR ALL OUTPUTS**!\n",
        "\n",
        "Recall that you are not restricted to <font color=\"red\">R</font>\n",
        "<font color=\"green\">G</font>\n",
        "<font color=\"blue\">B</font> at all!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aqe77tEeU-yz"
      },
      "source": [
        "# Part I: Manual threshold determination.\n",
        "You can determine as many thresholds as you like.  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzpeYFNPFIys"
      },
      "source": [
        "### Add explanations of what you do and why regarding the code(s) below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "F3jwSMH9U-YE"
      },
      "outputs": [],
      "source": [
        "# your prep code\n",
        "\n",
        "\n",
        "def plot_hsv_histogram(img_path):\n",
        "    \"\"\"\n",
        "    this is a function to plot the histogram of the HSV channels of an image\n",
        "    input:\n",
        "        img_path: the path of the image\n",
        "    output:\n",
        "        None\n",
        "        example:\n",
        "        plot_hsv_histogram('img_path')\n",
        "    \n",
        "    created for learning purposes of opencv library and to play with images\n",
        "    \"\"\"\n",
        "    # Load image\n",
        "    img_read_BGR = cv.imread(img_path)\n",
        "    img_read_RGB = cv.cvtColor(img_read_BGR, cv.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
        "    img_read_HSV = cv.cvtColor(img_read_BGR, cv.COLOR_BGR2HSV)  # Convert BGR to HSV\n",
        "\n",
        "    # Separate the H, S, and V channels\n",
        "    H, S, V = cv.split(img_read_HSV)\n",
        "\n",
        "    # Plot histograms\n",
        "    plt.figure(figsize=(16, 6))\n",
        "\n",
        "    plt.subplot(1, 4, 1)\n",
        "    plt.hist(H.ravel(), bins=180, range=[0, 179], color='orange', alpha=0.7)\n",
        "    plt.title('Hue Histogram')\n",
        "    plt.xlabel('Hue (0-179)')\n",
        "    plt.ylabel('Frequency')\n",
        "\n",
        "    plt.subplot(1, 4, 2)\n",
        "    plt.hist(S.ravel(), bins=256, range=[0, 255], color='green', alpha=0.7)\n",
        "    plt.title('Saturation Histogram')\n",
        "    plt.xlabel('Saturation (0-255)')\n",
        "    plt.ylabel('Frequency')\n",
        "\n",
        "    plt.subplot(1, 4, 3)\n",
        "    plt.hist(V.ravel(), bins=256, range=[0, 255], color='blue', alpha=0.7)\n",
        "    plt.title('Value Histogram')\n",
        "    plt.xlabel('Value (0-255)')\n",
        "    plt.ylabel('Frequency')\n",
        "\n",
        "    plt.subplot(1, 4, 4)\n",
        "    plt.imshow(img_read_RGB)\n",
        "    plt.title('Original Image')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_RGB_histogram(image_path):\n",
        "    \"\"\"\n",
        "    Reads an image from the given path and plots histograms for R, G, and B channels.\n",
        "    Args:\n",
        "        image_path: Path to the image file.\n",
        "\n",
        "    created for if rgb channels are enough or HSV or other space is needed\n",
        "    \"\"\"\n",
        "    # Load the image\n",
        "    img_read_BGR = cv.imread(image_path)\n",
        "    img_read_RGB = cv.cvtColor(img_read_BGR, cv.COLOR_BGR2RGB)  # Convert to RGB for consistent color channels\n",
        "\n",
        "    # Split into R, G, B channels\n",
        "    R, G, B = cv.split(img_read_RGB)\n",
        "\n",
        "    # Plot histograms\n",
        "    plt.figure(figsize=(16, 6))\n",
        "\n",
        "    plt.subplot(1, 4, 1)\n",
        "    plt.hist(R.ravel(), bins=256, range=[0, 256], color='r', alpha=0.7)\n",
        "    plt.title('Red Channel Histogram')\n",
        "    plt.xlabel('Intensity Value')\n",
        "    plt.ylabel('Frequency')\n",
        "\n",
        "    plt.subplot(1, 4, 2)\n",
        "    plt.hist(G.ravel(), bins=256, range=[0, 256], color='g', alpha=0.7)\n",
        "    plt.title('Green Channel Histogram')\n",
        "    plt.xlabel('Intensity Value')\n",
        "    plt.ylabel('Frequency')\n",
        "\n",
        "    plt.subplot(1, 4, 3)\n",
        "    plt.hist(B.ravel(), bins=256, range=[0, 256], color='b', alpha=0.7)\n",
        "    plt.title('Blue Channel Histogram')\n",
        "    plt.xlabel('Intensity Value')\n",
        "    plt.ylabel('Frequency')\n",
        "\n",
        "    plt.subplot(1, 4, 4)\n",
        "    plt.imshow(img_read_RGB,cmap='gray')\n",
        "    plt.title('Original Image')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def hsv_to_cv_ranges(h,  s, v):\n",
        "    \"\"\"\n",
        "    Convert general HSV ranges to OpenCV-compatible ranges.\n",
        "\n",
        "    Args:\n",
        "        h_min (float): Minimum Hue (0-360).\n",
        "        h_max (float): Maximum Hue (0-360).\n",
        "        s_min (float): Minimum Saturation (0-100).\n",
        "        s_max (float): Maximum Saturation (0-100).\n",
        "        v_min (float): Minimum Value (0-100).\n",
        "        v_max (float): Maximum Value (0-100).\n",
        "\n",
        "    Returns:\n",
        "        Tuple: Converted ranges in OpenCV format.\n",
        "        (h_min_cv, h_max_cv, s_min_cv, s_max_cv, v_min_cv, v_max_cv)\n",
        "    \"\"\"\n",
        "    # Convert H range (0-360) to OpenCV H range (0-180)\n",
        "    h_cv = int((h / 360) * 180)\n",
        "\n",
        "    # Convert S and V ranges (0-100) to OpenCV range (0-255)\n",
        "    s_cv = int((s / 100) * 255)\n",
        "    v_cv = int((v / 100) * 255)\n",
        "\n",
        "    return h_cv, s_cv, v_cv\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "4cqBJo8rVBuL"
      },
      "outputs": [],
      "source": [
        "# potentially more code\n",
        "#plot_hsv_histogram('AppleOrange/AorO1.jpg')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_rJGzeAVD0u"
      },
      "source": [
        "## ```AorO()``` function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "raXe6Vn6ODky"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "You are to properly implement the following function so that\n",
        "Apples become magenta, orange blue in color, and rest is blurred where blurring is visually detectable.\n",
        "\n",
        "'''\n",
        "\n",
        "\n",
        "def AorO(img_path):\n",
        "    \"\"\"\n",
        "    This function takes the path of an image, loads the image,\n",
        "    converts the color of apples to magenta, oranges to blue, and blurs the rest.\n",
        "    Shading (brightness) is preserved for apples and oranges.\n",
        "    Returns the modified image.\n",
        "    \"\"\"\n",
        "    # Input validation and image loading\n",
        "    if not isinstance(img_path, str):\n",
        "        print(\"Error: Image path must be a string.\")\n",
        "        return None\n",
        "\n",
        "    if not img_path.lower().endswith((\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tiff\")):\n",
        "        print(\"Error: Invalid file extension. Supported extensions are .jpg, .jpeg, .png, .bmp, .tiff\")\n",
        "        return None\n",
        "\n",
        "    img_read = cv.imread(img_path)\n",
        "    if img_read is None:\n",
        "        print(f\"Error: Unable to load the image at '{img_path}'. The file may not exist or be corrupted.\")\n",
        "        return None\n",
        "\n",
        "    if len(img_read.shape) != 3 or img_read.shape[2] != 3:\n",
        "        print(\"Error: The input image is not a valid color image with three channels.\")\n",
        "        return None\n",
        "    \n",
        "    hsv_img = cv.cvtColor(img_read, cv.COLOR_BGR2HSV)\n",
        "\n",
        "    # Define thresholds for apples and oranges in HSV\n",
        "    apple_lower = np.array([2, 150, 0])    \n",
        "    apple_upper = np.array([15, 255, 255])\n",
        "    orange_lower = np.array([10, 150, 0])\n",
        "    orange_upper = np.array([35, 255, 255])\n",
        "\n",
        "    # Create masks for apples and oranges\n",
        "    apple_mask = cv.inRange(hsv_img, apple_lower, apple_upper)\n",
        "    orange_mask = cv.inRange(hsv_img, orange_lower, orange_upper)\n",
        "\n",
        "    # Initialize result HSV image as a copy of the original\n",
        "    result_hsv = hsv_img.copy()\n",
        "\n",
        "    # Define HSV colors for magenta (apples) and blue (oranges)\n",
        "    magenta_hsv = np.array([150, 255, 255], dtype=np.uint8)  # Hue: 150\n",
        "    blue_hsv = np.array([105, 255, 255], dtype=np.uint8)     # Hue: 105\n",
        "\n",
        "    # Apply Hue and Saturation changes for apple mask, keep original Value\n",
        "    result_hsv[apple_mask > 0, 0] = magenta_hsv[0]  # Hue\n",
        "    result_hsv[apple_mask > 0, 1] = magenta_hsv[1]  # Saturation\n",
        "\n",
        "    # Apply Hue and Saturation changes for orange mask, keep original Value\n",
        "    result_hsv[orange_mask > 0, 0] = blue_hsv[0]  # Hue\n",
        "    result_hsv[orange_mask > 0, 1] = blue_hsv[1]  # Saturation\n",
        "\n",
        "    # Convert HSV result back to BGR\n",
        "    result_bgr = cv.cvtColor(result_hsv, cv.COLOR_HSV2BGR)\n",
        "\n",
        "    # Blur the background\n",
        "    blur_mask = cv.bitwise_not(cv.bitwise_or(apple_mask, orange_mask))\n",
        "    blur = cv.GaussianBlur(img_read, (31, 31), 0)\n",
        "    result_bgr[blur_mask > 0] = blur[blur_mask > 0]\n",
        "\n",
        "    return result_bgr\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oP7Phy3HDjyy"
      },
      "source": [
        "# Part II: Use some clustering methods to find thresholds automatically\n",
        "Assuming that there are apples and oranges in the image, analyze the colors in the image (such as histograms, or anything else you find fit), run some clustering algorithms on them and generate the image."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5AMHo0cFQSx"
      },
      "source": [
        "### Add explanations of what you do and why regarding the code(s) below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "jo2IOUkLFDXf"
      },
      "outputs": [],
      "source": [
        "# your prep code\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def visualize_dominant_colors(img_path, num_clusters=3):\n",
        "    \"\"\"\n",
        "    Extract and visualize dominant colors in an image using K-Means clustering.\n",
        "    \n",
        "    Args:\n",
        "        img_path (str): Path to the input image.\n",
        "        num_clusters (int): Number of color clusters.\n",
        "    \n",
        "    Returns:\n",
        "        None: Displays the original image and a bar plot of dominant colors.\n",
        "    \"\"\"\n",
        "    # Load image and convert to RGB\n",
        "    img_bgr = cv.imread(img_path)\n",
        "    img_rgb = cv.cvtColor(img_bgr, cv.COLOR_BGR2RGB)\n",
        "    \n",
        "    # Flatten the image\n",
        "    img_flat = img_rgb.reshape((-1, 3))\n",
        "    \n",
        "    # Apply K-Means clustering\n",
        "    kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
        "    kmeans.fit(img_flat)\n",
        "    \n",
        "    # Extract cluster centers (dominant colors) and labels\n",
        "    dominant_colors = kmeans.cluster_centers_.astype(int)\n",
        "    labels = kmeans.labels_\n",
        "    \n",
        "    # Count the pixels in each cluster\n",
        "    label_counts = np.bincount(labels)\n",
        "    \n",
        "    # Sort clusters by pixel count\n",
        "    sorted_indices = np.argsort(-label_counts)\n",
        "    dominant_colors = dominant_colors[sorted_indices]\n",
        "    label_counts = label_counts[sorted_indices]\n",
        "    \n",
        "    # Normalize counts to calculate proportions\n",
        "    proportions = label_counts / sum(label_counts)\n",
        "    \n",
        "    # Plot the original image\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(img_rgb)\n",
        "    plt.axis('off')\n",
        "    plt.title(\"Original Image\")\n",
        "    \n",
        "    # Plot the dominant colors\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.bar(range(num_clusters), proportions, color=[dominant_colors[i] / 255 for i in range(num_clusters)])\n",
        "    plt.title(\"Dominant Colors\")\n",
        "    plt.xlabel(\"Clusters\")\n",
        "    plt.ylabel(\"Proportion\")\n",
        "    plt.xticks(range(num_clusters), [f\"Cluster {i+1}\" for i in range(num_clusters)])\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AFZjrc30FEuh"
      },
      "outputs": [],
      "source": [
        "# potentially more code\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "\n",
        "# Read image\n",
        "img = cv.imread('AppleOrange/AorO7.jpg')\n",
        "\n",
        "# Convert from BGR to HSV\n",
        "img_hsv = cv.cvtColor(img, cv.COLOR_BGR2HSV)\n",
        "\n",
        "# Apply sharpening kernel\n",
        "sharpen_kernel = np.array([[0, -1, 0], \n",
        "                            [-1, 5, -1], \n",
        "                            [0, -1, 0]])\n",
        "sharpened_img = cv.filter2D(img_hsv, -1, sharpen_kernel)\n",
        "\n",
        "# Apply Erosion after sharpening\n",
        "kernel = np.ones((5, 5), np.uint8)  # Define a kernel for erosion\n",
        "eroded_img = cv.erode(sharpened_img, kernel, iterations=1)\n",
        "\n",
        "# Convert the eroded HSV image back to BGR for display\n",
        "eroded_bgr = cv.cvtColor(eroded_img, cv.COLOR_HSV2BGR)\n",
        "\n",
        "# Split the HSV channels from the eroded image\n",
        "h, s, v = cv.split(eroded_img)\n",
        "\n",
        "# Flatten the channels for visualization\n",
        "h = h.flatten()\n",
        "s = s.flatten()\n",
        "v = v.flatten()\n",
        "\n",
        "# Normalize the HSV values to ensure better visualization in 3D scatter\n",
        "h = h / 180.0\n",
        "s = s / 255.0\n",
        "v = v / 255.0\n",
        "\n",
        "# Plotting\n",
        "fig = plt.figure(figsize=(15, 8))\n",
        "\n",
        "# Subplot 1: Sharpened Image\n",
        "ax1 = fig.add_subplot(1, 3, 1)\n",
        "ax1.imshow(cv.cvtColor(cv.cvtColor(sharpened_img, cv.COLOR_HSV2BGR), cv.COLOR_BGR2RGB))\n",
        "ax1.axis('off')\n",
        "ax1.set_title('Sharpened Image')\n",
        "\n",
        "# Subplot 2: Eroded Image Output\n",
        "ax2 = fig.add_subplot(1, 3, 2)\n",
        "ax2.imshow(cv.cvtColor(eroded_bgr, cv.COLOR_BGR2RGB))\n",
        "ax2.axis('off')\n",
        "ax2.set_title('Eroded Image')\n",
        "\n",
        "# Subplot 3: 3D Scatter Plot\n",
        "ax3 = fig.add_subplot(1, 3, 3, projection='3d')\n",
        "scatter = ax3.scatter(h, s, v, c=np.array([h, s, v]).T, marker='o', s=1, alpha=0.6)\n",
        "ax3.set_xlabel('Hue Channel')\n",
        "ax3.set_ylabel('Saturation Channel')\n",
        "ax3.set_zlabel('Value Channel')\n",
        "ax3.set_title('3D HSV Scatter Plot (After Erosion)')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osrOY4fpE8Lz"
      },
      "source": [
        "## ```AorO2()``` function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "FUp5z6MHm730"
      },
      "outputs": [],
      "source": [
        "# '''\n",
        "# You are to properly implement the following function so that\n",
        "# Apples become magenta, orange blue in color, and rest is blurred where blurring is visually detectable.\n",
        "\n",
        "# '''\n",
        "# def AorO2(img_path):\n",
        "#     \"\"\"\n",
        "#     This function applies a two-stage thresholding approach to segment apples and oranges\n",
        "#     from the background. Apples are converted to magenta, oranges to blue, and the rest is blurred.\n",
        "\n",
        "#     Args:\n",
        "#         img_path (str): Path to the input image.\n",
        "\n",
        "#     Returns:\n",
        "#         result (ndarray): The modified image with segmentation applied.\n",
        "#     \"\"\"\n",
        "#     # Load image\n",
        "#     img_read = cv.imread(img_path)\n",
        "#     if img_read is None:\n",
        "#         raise ValueError(f\"Image at path '{img_path}' could not be loaded.\")\n",
        "\n",
        "#     # Convert to HSV color space\n",
        "#     hsv_img = cv.cvtColor(img_read, cv.COLOR_BGR2HSV)\n",
        "#     h, s, v = cv.split(hsv_img)\n",
        "\n",
        "#     # Stage 1: Global Thresholding (Suppress Background)\n",
        "#     global_hue_lower, global_hue_upper = 0, 180  # Consider all hues\n",
        "#     global_saturation_lower, global_saturation_upper = 50, 255  # Suppress low-saturation areas\n",
        "\n",
        "#     global_mask = cv.inRange(hsv_img, \n",
        "#                              (global_hue_lower, global_saturation_lower, 0),\n",
        "#                              (global_hue_upper, global_saturation_upper, 255))\n",
        "\n",
        "#     # Apply global mask to filter the HSV image\n",
        "#     hsv_filtered = cv.bitwise_and(hsv_img, hsv_img, mask=global_mask)\n",
        "\n",
        "#     # Stage 2: Local Thresholding (Refine Foreground)\n",
        "#     # Use Otsu's method on the saturation channel of the filtered image\n",
        "#     _, local_thresh_saturation = cv.threshold(hsv_filtered[:, :, 1], 0, 255, cv.THRESH_BINARY + cv.THRESH_OTSU)\n",
        "\n",
        "#     # Combine masks\n",
        "#     combined_mask = cv.bitwise_and(global_mask, local_thresh_saturation)\n",
        "\n",
        "#     # Apply the combined mask\n",
        "#     segmented_hsv = cv.bitwise_and(hsv_img, hsv_img, mask=combined_mask)\n",
        "\n",
        "#     # Identify clusters: Apples (red hues) and Oranges (orange hues)\n",
        "#     apple_lower = np.array([0, 30, 50])    \n",
        "#     apple_upper = np.array([14, 255, 255])\n",
        "#     orange_lower = np.array([14, 30, 50])\n",
        "#     orange_upper = np.array([24, 255, 255])\n",
        "\n",
        "#     apple_mask = cv.inRange(segmented_hsv, apple_lower, apple_upper)\n",
        "#     orange_mask = cv.inRange(segmented_hsv, orange_lower, orange_upper)\n",
        "\n",
        "#     # Create magenta (apples) and blue (oranges) in BGR\n",
        "#     magenta = np.array([255, 0, 255], dtype=np.uint8)\n",
        "#     blue = np.array([255, 0, 0], dtype=np.uint8)\n",
        "\n",
        "#     # Initialize result\n",
        "#     result = img_read.copy()\n",
        "\n",
        "#     # Apply colors\n",
        "#     result[apple_mask > 0] = magenta\n",
        "#     result[orange_mask > 0] = blue\n",
        "\n",
        "#     # Create blur mask (areas not identified as apple or orange)\n",
        "#     blur_mask = cv.bitwise_not(cv.bitwise_or(apple_mask, orange_mask))\n",
        "\n",
        "#     # Apply blur to remaining regions\n",
        "#     blur = cv.GaussianBlur(img_read, (31, 31), 0)\n",
        "#     result[blur_mask > 0] = blur[blur_mask > 0]\n",
        "\n",
        "#     return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def AorO2(img_path):\n",
        "    \"\"\"\n",
        "    AorO2 using K-Means clustering with dynamic cluster assignment and HSV shading preservation.\n",
        "    \n",
        "    Args:\n",
        "        img_path (str): Path to the input image.\n",
        "        num_clusters (int): Number of clusters for K-Means.\n",
        "        debug (bool): Enable debug mode for visualizing clusters.(removed for submission)\n",
        "    \n",
        "    Returns:\n",
        "        result (ndarray): Processed image with apples, oranges, and background.\n",
        "    \"\"\"\n",
        "    # Input validation and image loading\n",
        "    if not isinstance(img_path, str):\n",
        "        print(\"Error: Image path must be a string.\")\n",
        "        return None\n",
        "\n",
        "    if not img_path.lower().endswith((\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tiff\")):\n",
        "        print(\"Error: Invalid file extension. Supported extensions are .jpg, .jpeg, .png, .bmp, .tiff\")\n",
        "        return None\n",
        "\n",
        "    img_read = cv.imread(img_path)\n",
        "    if img_read is None:\n",
        "        print(f\"Error: Unable to load the image at '{img_path}'. The file may not exist or be corrupted.\")\n",
        "        return None\n",
        "\n",
        "    if len(img_read.shape) != 3 or img_read.shape[2] != 3:\n",
        "        print(\"Error: The input image is not a valid color image with three channels.\")\n",
        "        return None\n",
        "\n",
        "    num_clusters = 10\n",
        "    \n",
        "\n",
        "    # Preprocess: Sharpen the image\n",
        "    sharpen_kernel = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]])\n",
        "    img_sharpened = cv.filter2D(img_read, -1, sharpen_kernel)\n",
        "\n",
        "    # Convert to HSV color space\n",
        "    hsv_img = cv.cvtColor(img_sharpened, cv.COLOR_BGR2HSV)\n",
        "    h, w, _ = hsv_img.shape\n",
        "\n",
        "    # Flatten HSV for clustering\n",
        "    flat_hsv = hsv_img.reshape((-1, 3))\n",
        "\n",
        "    # Perform K-Means clustering\n",
        "    kmeans = KMeans(n_clusters=num_clusters, random_state=42, max_iter=300)\n",
        "    kmeans.fit(flat_hsv)\n",
        "    labels = kmeans.labels_\n",
        "    centers = kmeans.cluster_centers_\n",
        "\n",
        "\n",
        "    # Reshape labels to the original image dimensions\n",
        "    cluster_map = labels.reshape((h, w))\n",
        "\n",
        "    # Initialize masks\n",
        "    apple_mask = np.zeros((h, w), dtype=np.uint8)\n",
        "    orange_mask = np.zeros((h, w), dtype=np.uint8)\n",
        "    background_mask = np.zeros((h, w), dtype=np.uint8)\n",
        "\n",
        "    # Dynamically assign clusters based on center values\n",
        "    for i, center in enumerate(centers):\n",
        "        hue, sat, val = center\n",
        "        if 10 <= hue <= 35 and sat > 200 :  # Likely orange\n",
        "            orange_mask[cluster_map == i] = 255\n",
        "        elif (2 <= hue <= 15 or 170 <= hue <= 179) and 100 <= sat <= 200 :  # Likely apple\n",
        "            apple_mask[cluster_map == i] = 255\n",
        "        else:  # Likely background\n",
        "            background_mask[cluster_map == i] = 255\n",
        "\n",
        "    # Refine masks with morphological operations\n",
        "    kernel = cv.getStructuringElement(cv.MORPH_ELLIPSE, (5, 5))\n",
        "    apple_mask = cv.dilate(apple_mask, kernel, iterations=2)\n",
        "    orange_mask = cv.dilate(orange_mask, kernel, iterations=2)\n",
        "\n",
        "    # Create HSV colors for magenta (apples) and blue (oranges)\n",
        "    magenta_hsv = np.array([150, 255, 255], dtype=np.uint8)\n",
        "    blue_hsv = np.array([105, 255, 255], dtype=np.uint8)\n",
        "\n",
        "    # Apply HSV changes to the original image\n",
        "    result_hsv = hsv_img.copy()\n",
        "\n",
        "    # Apply Hue and Saturation for apple mask, keep original Value\n",
        "    result_hsv[apple_mask > 0, 0] = magenta_hsv[0]  # Hue\n",
        "    result_hsv[apple_mask > 0, 1] = magenta_hsv[1]  # Saturation\n",
        "\n",
        "    # Apply Hue and Saturation for orange mask, keep original Value\n",
        "    result_hsv[orange_mask > 0, 0] = blue_hsv[0]  # Hue\n",
        "    result_hsv[orange_mask > 0, 1] = blue_hsv[1]  # Saturation\n",
        "\n",
        "    # Convert HSV back to BGR for final result\n",
        "    result_bgr = cv.cvtColor(result_hsv, cv.COLOR_HSV2BGR)\n",
        "\n",
        "    # Blur the background\n",
        "    blur_mask = cv.bitwise_not(cv.bitwise_or(apple_mask, orange_mask))\n",
        "    blur = cv.GaussianBlur(img_read, (31, 31), 0)\n",
        "    result_bgr[blur_mask > 0] = blur[blur_mask > 0]\n",
        "\n",
        "\n",
        "\n",
        "    return result_bgr\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Explanation of the Function\n",
        "\n",
        "The `AorO2` function processes an image to:\n",
        "1. Identify and highlight apples and oranges using specific colors (magenta and blue).\n",
        "2. Blur the background for aesthetic distinction.\n",
        "3. Use K-Means clustering and HSV color space for dynamic and robust color-based segmentation.\n",
        "\n",
        "### Step-by-Step Breakdown\n",
        "\n",
        "1. **Input Validation**:\n",
        "   - Checks if the input path is a string.\n",
        "   - Ensures the file extension is valid (`.jpg`, `.jpeg`, `.png`, `.bmp`, `.tiff`).\n",
        "   - Attempts to load the image using OpenCV (`cv.imread`).\n",
        "   - Validates that the loaded image is a 3-channel color image.\n",
        "\n",
        "2. **Preprocessing**:\n",
        "   - A sharpening filter (`sharpen_kernel`) is applied to the image to enhance edges and details before processing.\n",
        "\n",
        "3. **Color Space Conversion**:\n",
        "   - Converts the sharpened image from BGR (Blue-Green-Red) to HSV (Hue-Saturation-Value) format for better color differentiation.\n",
        "\n",
        "4. **Data Preparation for Clustering**:\n",
        "   - Flattens the HSV image into a 2D array (`flat_hsv`) where each pixel's HSV values are treated as a data point.\n",
        "\n",
        "5. **K-Means Clustering**:\n",
        "   - Performs clustering on the flattened data to group pixels into `num_clusters` (default: 10) based on their color properties.\n",
        "   - Outputs:\n",
        "     - `labels`: Cluster assignments for each pixel.\n",
        "     - `centers`: HSV values representing the cluster centers.\n",
        "\n",
        "6. **Cluster Assignment**:\n",
        "   - Reshapes the cluster labels back into the original image dimensions (`cluster_map`).\n",
        "   - Dynamically assigns clusters to apples, oranges, and the background based on heuristics:\n",
        "     - **Apples**: Hue between 2-15 or 170-179, medium saturation (100-200).\n",
        "     - **Oranges**: Hue between 10-35, high saturation (>200).\n",
        "     - **Background**: Anything not classified as apple or orange.\n",
        "\n",
        "7. **Refinement**:\n",
        "   - Applies morphological dilation using an elliptical kernel to clean up and fill small gaps in the masks.\n",
        "\n",
        "8. **Color Application**:\n",
        "   - Converts masks into specific HSV colors:\n",
        "     - **Apples**: Magenta (`Hue=150`).\n",
        "     - **Oranges**: Blue (`Hue=105`).\n",
        "   - Preserves the original Value channel (shading/brightness) to maintain the realistic appearance of the fruits.\n",
        "\n",
        "9. **Reconstruction**:\n",
        "   - Converts the processed HSV image (`result_hsv`) back to BGR format for visualization.\n",
        "\n",
        "10. **Background Blurring**:\n",
        "    - Creates a blur mask for areas not identified as apples or oranges.\n",
        "    - Applies a Gaussian blur to those areas for visual emphasis.\n",
        "\n",
        "11. **Return**:\n",
        "    - Returns the final processed image (`result_bgr`) with:\n",
        "      - Apples in magenta.\n",
        "      - Oranges in blue.\n",
        "      - Blurred background.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0fT5O_lDVvy"
      },
      "source": [
        "# My test will be performed below\n",
        "Using my own code either at the end of this file or separately on my computer, I will just call the  ```AorO()``` or ```AorO2() functions in different ways and enjoy the outcomes :)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
