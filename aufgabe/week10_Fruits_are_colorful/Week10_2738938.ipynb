{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vltmNTJUOO1A"
      },
      "source": [
        "# Full Name: Çağdaş Güven\n",
        "\n",
        "# Student ID: 2738938"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EX3aiSdnOII7"
      },
      "source": [
        "# Try to Tell Apples, Oranges and else apart\n",
        "\n",
        "Images for this assignment are provided at github and they will be automatically downloaded right after imports. When the files are unzip there should be a folder:  ```AppleOrange```.\n",
        "These are sample images, you can test with more if you want. While testing just for fun, I can try other stuff as well.\n",
        "\n",
        "Your objective is to convert <font color=\"magenta\"> **Apples to magenta** </font>, <font color=\"blue\"> **Oranges to Blue** </font> , end blur everything else! While changing color, try to keep the original shading (i.e. try not provide a flat single color if possible, keep the shadings to the best you can).  \n",
        "\n",
        "<font color=\"red\">Do not be **too picky** and lose too much time</font>. Variety of images are provided so that you get the idea that generalizable / perfect filters are not easy to build. Yet your function is expected to work on more than one image at an acceptable level.  \n",
        "\n",
        "By the same token, you can use the ```fakes```, also for for fun to see how your algorighm works on unrealted images, and why a general filter is not that easy...  \n",
        "\n",
        "At the end as usual you are expected to **clear all outputs** and then save this file as **Week10_student_id.ipynb** and upload to the assignment at [ODTU Class](https://odtuclass2024f.metu.edu.tr/mod/assign/view.php?id=100364).  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zLzqIVXJSCRU"
      },
      "source": [
        "# imports as usual\n",
        "You are only allowed to use concepts related to what we have seen in class and use only the following imports. You can import sub-libraries with new names etc. but NO NEW LIBRARIES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eQZIUC0gSQ7F"
      },
      "outputs": [],
      "source": [
        "# not that all of them are necessary, but you are not allowed to import any new library\n",
        "# yet as before, you can import sub libraries: i.e.:\n",
        "#       from skimage import measure\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as pimg # check this out this is new\n",
        "from numpy import cos, arccos, sin, pi, round\n",
        "from numpy.linalg import matrix_rank as rank\n",
        "from numpy.linalg import svd, eig\n",
        "from scipy.linalg import orth\n",
        "import cv2 as cv\n",
        "from PIL import Image # good old pillow\n",
        "import sklearn as skl # famous sci-kit learn\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import pairwise_distances_argmin\n",
        "from sklearn.utils import shuffle\n",
        "from skimage.exposure import histogram\n",
        "import skimage as ski # equally famous sci-kit image\n",
        "!rm bug_numpy_utils.py 2>/dev/null  # at the first run file does not exits but error should print\n",
        "!wget https://raw.githubusercontent.com/bugrakoku/bug_python_utils/main/bug_numpy_utils.py\n",
        "from bug_numpy_utils import MatPrint, CData, text2mat # note that once these files are downloaded you can read their content.\n",
        "!rm me536utils.py 2>/dev/null  # at the first run file does not exits but error should print\n",
        "!wget https://raw.githubusercontent.com/bugrakoku/bug_python_utils/main/me536utils.py\n",
        "from me536utils import RotMat"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1-LOxSkVzxH"
      },
      "source": [
        "## get images\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "35qHlbaGV47L"
      },
      "outputs": [],
      "source": [
        "# !rm AppleOrange.zip 2>/dev/null # just in case\n",
        "# !wget https://github.com/bugrakoku/data4all/raw/main/AppleOrange.zip # get the zip file\n",
        "# !unzip AppleOrange.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jREEYYBZS4vQ"
      },
      "source": [
        "# Get prepared\n",
        "Below you can check images, perform tests runs, find critical color values etc.  \n",
        "Leave all your preparation code so that I can see how you have reached the final implementation of the function. This part I will NOT run for evaluation! I will only run the ```AorO()``` and ```AorO2()``` functions in my tests!  \n",
        "\n",
        "You can add as many code and text cells as you like below. But at the end, as I said above, I will just call the ```AorO()``` or ```AorO2()``` function.  \n",
        "And please **DO CLEAR ALL OUTPUTS**!\n",
        "\n",
        "Recall that you are not restricted to <font color=\"red\">R</font>\n",
        "<font color=\"green\">G</font>\n",
        "<font color=\"blue\">B</font> at all!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aqe77tEeU-yz"
      },
      "source": [
        "# Part I: Manual threshold determination.\n",
        "You can determine as many thresholds as you like.  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzpeYFNPFIys"
      },
      "source": [
        "### Add explanations of what you do and why regarding the code(s) below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "F3jwSMH9U-YE"
      },
      "outputs": [],
      "source": [
        "# your prep code\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "\n",
        "def plot_hsv_histogram(img_path):\n",
        "    # Load image\n",
        "    img_read_BGR = cv.imread(img_path)\n",
        "    img_read_RGB = cv.cvtColor(img_read_BGR, cv.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
        "    img_read_HSV = cv.cvtColor(img_read_BGR, cv.COLOR_BGR2HSV)  # Convert BGR to HSV\n",
        "\n",
        "    # Separate the H, S, and V channels\n",
        "    H, S, V = cv.split(img_read_HSV)\n",
        "\n",
        "    # Plot histograms\n",
        "    plt.figure(figsize=(16, 6))\n",
        "\n",
        "    plt.subplot(1, 4, 1)\n",
        "    plt.hist(H.ravel(), bins=180, range=[0, 179], color='orange', alpha=0.7)\n",
        "    plt.title('Hue Histogram')\n",
        "    plt.xlabel('Hue (0-179)')\n",
        "    plt.ylabel('Frequency')\n",
        "\n",
        "    plt.subplot(1, 4, 2)\n",
        "    plt.hist(S.ravel(), bins=256, range=[0, 255], color='green', alpha=0.7)\n",
        "    plt.title('Saturation Histogram')\n",
        "    plt.xlabel('Saturation (0-255)')\n",
        "    plt.ylabel('Frequency')\n",
        "\n",
        "    plt.subplot(1, 4, 3)\n",
        "    plt.hist(V.ravel(), bins=256, range=[0, 255], color='blue', alpha=0.7)\n",
        "    plt.title('Value Histogram')\n",
        "    plt.xlabel('Value (0-255)')\n",
        "    plt.ylabel('Frequency')\n",
        "\n",
        "    plt.subplot(1, 4, 4)\n",
        "    plt.imshow(img_read_RGB)\n",
        "    plt.title('Original Image')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_RGB_histogram(image_path):\n",
        "    \"\"\"\n",
        "    Reads an image from the given path and plots histograms for R, G, and B channels.\n",
        "    Args:\n",
        "        image_path: Path to the image file.\n",
        "    \"\"\"\n",
        "    # Load the image\n",
        "    img_read_BGR = cv.imread(image_path)\n",
        "    img_read_RGB = cv.cvtColor(img_read_BGR, cv.COLOR_BGR2RGB)  # Convert to RGB for consistent color channels\n",
        "\n",
        "    # Split into R, G, B channels\n",
        "    R, G, B = cv.split(img_read_RGB)\n",
        "\n",
        "    # Plot histograms\n",
        "    plt.figure(figsize=(16, 6))\n",
        "\n",
        "    plt.subplot(1, 4, 1)\n",
        "    plt.hist(R.ravel(), bins=256, range=[0, 256], color='r', alpha=0.7)\n",
        "    plt.title('Red Channel Histogram')\n",
        "    plt.xlabel('Intensity Value')\n",
        "    plt.ylabel('Frequency')\n",
        "\n",
        "    plt.subplot(1, 4, 2)\n",
        "    plt.hist(G.ravel(), bins=256, range=[0, 256], color='g', alpha=0.7)\n",
        "    plt.title('Green Channel Histogram')\n",
        "    plt.xlabel('Intensity Value')\n",
        "    plt.ylabel('Frequency')\n",
        "\n",
        "    plt.subplot(1, 4, 3)\n",
        "    plt.hist(B.ravel(), bins=256, range=[0, 256], color='b', alpha=0.7)\n",
        "    plt.title('Blue Channel Histogram')\n",
        "    plt.xlabel('Intensity Value')\n",
        "    plt.ylabel('Frequency')\n",
        "\n",
        "    plt.subplot(1, 4, 4)\n",
        "    plt.imshow(img_read_RGB,cmap='gray')\n",
        "    plt.title('Original Image')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def hsv_to_cv_ranges(h,  s, v):\n",
        "    \"\"\"\n",
        "    Convert general HSV ranges to OpenCV-compatible ranges.\n",
        "\n",
        "    Args:\n",
        "        h_min (float): Minimum Hue (0-360).\n",
        "        h_max (float): Maximum Hue (0-360).\n",
        "        s_min (float): Minimum Saturation (0-100).\n",
        "        s_max (float): Maximum Saturation (0-100).\n",
        "        v_min (float): Minimum Value (0-100).\n",
        "        v_max (float): Maximum Value (0-100).\n",
        "\n",
        "    Returns:\n",
        "        Tuple: Converted ranges in OpenCV format.\n",
        "        (h_min_cv, h_max_cv, s_min_cv, s_max_cv, v_min_cv, v_max_cv)\n",
        "    \"\"\"\n",
        "    # Convert H range (0-360) to OpenCV H range (0-180)\n",
        "    h_cv = int((h / 360) * 180)\n",
        "\n",
        "    # Convert S and V ranges (0-100) to OpenCV range (0-255)\n",
        "    s_cv = int((s / 100) * 255)\n",
        "    v_cv = int((v / 100) * 255)\n",
        "\n",
        "    return h_cv, s_cv, v_cv\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4cqBJo8rVBuL"
      },
      "outputs": [],
      "source": [
        "# potentially more code\n",
        "plot_hsv_histogram('AppleOrange/AorO1.jpg')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_RGB_histogram('apple.jpg')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_rJGzeAVD0u"
      },
      "source": [
        "## ```AorO()``` function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "raXe6Vn6ODky"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "You are to properly implement the following function so that\n",
        "Apples become magenta, orange blue in color, and rest is blurred where blurring is visually detectable.\n",
        "\n",
        "'''\n",
        "\n",
        "def AorO(img):\n",
        "    '''\n",
        "    this function takes the path of an image, loads the image\n",
        "    converts the color of apples to magenta, color of oranges to blue and blurs the rest\n",
        "    you are to use some hand crafted thresholds here\n",
        "    returns the modified image\n",
        "    '''\n",
        "\n",
        "    # Load image\n",
        "    img_read = cv.imread(img)\n",
        "    hsv_img = cv.cvtColor(img_read, cv.COLOR_BGR2HSV)\n",
        "\n",
        "    # Define thresholds for apples and oranges in HSV\n",
        "    apple_lower = np.array([2, 140, 50])    \n",
        "    apple_upper = np.array([179, 240, 255])\n",
        "    orange_lower = np.array([3, 150, 50])\n",
        "    orange_upper = np.array([25, 250, 255])\n",
        "\n",
        "    # Create masks for apples and oranges\n",
        "    apple_mask = cv.inRange(hsv_img, apple_lower, apple_upper)\n",
        "    orange_mask = cv.inRange(hsv_img, orange_lower, orange_upper)\n",
        "\n",
        "    # Create magenta (apples) and blue (oranges)\n",
        "    magenta = np.array([255, 0, 255], dtype=np.uint8)\n",
        "    blue = np.array([255, 0, 0], dtype=np.uint8)\n",
        "\n",
        "    # Apply colors\n",
        "    result = img_read.copy()\n",
        "    result[apple_mask > 0] = magenta\n",
        "    result[orange_mask > 0] = blue\n",
        "\n",
        "    # Blur the rest\n",
        "    blur_mask = ~(apple_mask | orange_mask)\n",
        "    blur = cv.GaussianBlur(img_read, (15, 15), 0)\n",
        "    result[blur_mask > 0] = blur[blur_mask > 0]\n",
        "\n",
        "    return result\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cvranges = hsv_to_cv_ranges(26, 80.6, 97.3)\n",
        "cvranges"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# def AorO(img):\n",
        "#     \"\"\"\n",
        "#     This function takes the path of an image, loads the image,\n",
        "#     converts the color of apples to magenta, color of oranges to blue, and blurs the rest.\n",
        "#     Uses RGB thresholds for segmentation.\n",
        "#     Returns the modified image.\n",
        "#     \"\"\"\n",
        "#     # Load the image\n",
        "#     img_read = cv.imread(img)\n",
        "#     #img_read = cv.cvtColor(img_read, cv.COLOR_BGR2RGB)  # Convert to RGB\n",
        "\n",
        "#     # Define thresholds for apples and oranges in BGR\n",
        "#     apple_lower = np.array([22, 23, 140])   # Example thresholds for apples\n",
        "#     apple_upper = np.array([190, 150, 220])\n",
        "#     orange_lower = np.array([3, 118, 180])  # Example thresholds for oranges\n",
        "#     orange_upper = np.array([110, 197, 253])\n",
        "\n",
        "#     # Create masks for apples and oranges\n",
        "#     apple_mask = cv.inRange(img_read, apple_lower, apple_upper)\n",
        "#     orange_mask = cv.inRange(img_read, orange_lower, orange_upper)\n",
        "\n",
        "#     # Create magenta (apples) and blue (oranges)\n",
        "#     magenta = np.array([255, 0, 255], dtype=np.uint8)\n",
        "#     blue = np.array([255, 0, 0], dtype=np.uint8)\n",
        "\n",
        "#     # Apply colors\n",
        "#     result = img_read.copy()\n",
        "#     result[apple_mask > 0] = magenta\n",
        "#     result[orange_mask > 0] = blue\n",
        "\n",
        "#     # Blur the rest\n",
        "#     blur_mask = ~(apple_mask | orange_mask)\n",
        "#     blur = cv.GaussianBlur(img_read, (15, 15), 0)\n",
        "#     result[blur_mask > 0] = blur[blur_mask > 0]\n",
        "\n",
        "#     return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "img_read =  cv.imread('AppleOrange/AorO5.jpg')\n",
        "result_imageS = cv.resize(img_read, (960, 540))\n",
        "\n",
        "cv.imshow('img_read', result_imageS)\n",
        "cv.waitKey(0)\n",
        "cv.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "result_image = AorO('AppleOrange/AorO7.jpg')\n",
        "result_imageS = cv.resize(result_image, (960, 540))\n",
        "cv.imshow('Processed Image', result_imageS)\n",
        "cv.waitKey(0)\n",
        "cv.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oP7Phy3HDjyy"
      },
      "source": [
        "# Part II: Use some clustering methods to find thresholds automatically\n",
        "Assuming that there are apples and oranges in the image, analyze the colors in the image (such as histograms, or anything else you find fit), run some clustering algorithms on them and generate the image."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5AMHo0cFQSx"
      },
      "source": [
        "### Add explanations of what you do and why regarding the code(s) below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "jo2IOUkLFDXf"
      },
      "outputs": [],
      "source": [
        "# your prep code\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def visualize_dominant_colors(img_path, num_clusters=3):\n",
        "    \"\"\"\n",
        "    Extract and visualize dominant colors in an image using K-Means clustering.\n",
        "    \n",
        "    Args:\n",
        "        img_path (str): Path to the input image.\n",
        "        num_clusters (int): Number of color clusters.\n",
        "    \n",
        "    Returns:\n",
        "        None: Displays the original image and a bar plot of dominant colors.\n",
        "    \"\"\"\n",
        "    # Load image and convert to RGB\n",
        "    img_bgr = cv.imread(img_path)\n",
        "    img_rgb = cv.cvtColor(img_bgr, cv.COLOR_BGR2RGB)\n",
        "    \n",
        "    # Flatten the image\n",
        "    img_flat = img_rgb.reshape((-1, 3))\n",
        "    \n",
        "    # Apply K-Means clustering\n",
        "    kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
        "    kmeans.fit(img_flat)\n",
        "    \n",
        "    # Extract cluster centers (dominant colors) and labels\n",
        "    dominant_colors = kmeans.cluster_centers_.astype(int)\n",
        "    labels = kmeans.labels_\n",
        "    \n",
        "    # Count the pixels in each cluster\n",
        "    label_counts = np.bincount(labels)\n",
        "    \n",
        "    # Sort clusters by pixel count\n",
        "    sorted_indices = np.argsort(-label_counts)\n",
        "    dominant_colors = dominant_colors[sorted_indices]\n",
        "    label_counts = label_counts[sorted_indices]\n",
        "    \n",
        "    # Normalize counts to calculate proportions\n",
        "    proportions = label_counts / sum(label_counts)\n",
        "    \n",
        "    # Plot the original image\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(img_rgb)\n",
        "    plt.axis('off')\n",
        "    plt.title(\"Original Image\")\n",
        "    \n",
        "    # Plot the dominant colors\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.bar(range(num_clusters), proportions, color=[dominant_colors[i] / 255 for i in range(num_clusters)])\n",
        "    plt.title(\"Dominant Colors\")\n",
        "    plt.xlabel(\"Clusters\")\n",
        "    plt.ylabel(\"Proportion\")\n",
        "    plt.xticks(range(num_clusters), [f\"Cluster {i+1}\" for i in range(num_clusters)])\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "AFZjrc30FEuh"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# potentially more code\n",
        "\n",
        "#visualize_dominant_colors('AppleOrange/AorO1.jpg', num_clusters=3)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "#read image\n",
        "img = cv.imread('AppleOrange/AorO1.jpg')\n",
        "\n",
        "#convert from BGR to RGB\n",
        "img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
        "\n",
        "#get rgb values from image to 1D array\n",
        "r, g, b = cv.split(img)\n",
        "r = r.flatten()\n",
        "g = g.flatten()\n",
        "b = b.flatten()\n",
        "\n",
        "#plotting \n",
        "fig = plt.figure()\n",
        "ax = Axes3D(fig)\n",
        "ax.scatter(r, g, b)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osrOY4fpE8Lz"
      },
      "source": [
        "## ```AorO2()``` function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "FUp5z6MHm730"
      },
      "outputs": [],
      "source": [
        "# '''\n",
        "# You are to properly implement the following function so that\n",
        "# Apples become magenta, orange blue in color, and rest is blurred where blurring is visually detectable.\n",
        "\n",
        "# '''\n",
        "# def AorO2(img_path):\n",
        "#     \"\"\"\n",
        "#     This function applies a two-stage thresholding approach to segment apples and oranges\n",
        "#     from the background. Apples are converted to magenta, oranges to blue, and the rest is blurred.\n",
        "\n",
        "#     Args:\n",
        "#         img_path (str): Path to the input image.\n",
        "\n",
        "#     Returns:\n",
        "#         result (ndarray): The modified image with segmentation applied.\n",
        "#     \"\"\"\n",
        "#     # Load image\n",
        "#     img_read = cv.imread(img_path)\n",
        "#     if img_read is None:\n",
        "#         raise ValueError(f\"Image at path '{img_path}' could not be loaded.\")\n",
        "\n",
        "#     # Convert to HSV color space\n",
        "#     hsv_img = cv.cvtColor(img_read, cv.COLOR_BGR2HSV)\n",
        "#     h, s, v = cv.split(hsv_img)\n",
        "\n",
        "#     # Stage 1: Global Thresholding (Suppress Background)\n",
        "#     global_hue_lower, global_hue_upper = 0, 180  # Consider all hues\n",
        "#     global_saturation_lower, global_saturation_upper = 50, 255  # Suppress low-saturation areas\n",
        "\n",
        "#     global_mask = cv.inRange(hsv_img, \n",
        "#                              (global_hue_lower, global_saturation_lower, 0),\n",
        "#                              (global_hue_upper, global_saturation_upper, 255))\n",
        "\n",
        "#     # Apply global mask to filter the HSV image\n",
        "#     hsv_filtered = cv.bitwise_and(hsv_img, hsv_img, mask=global_mask)\n",
        "\n",
        "#     # Stage 2: Local Thresholding (Refine Foreground)\n",
        "#     # Use Otsu's method on the saturation channel of the filtered image\n",
        "#     _, local_thresh_saturation = cv.threshold(hsv_filtered[:, :, 1], 0, 255, cv.THRESH_BINARY + cv.THRESH_OTSU)\n",
        "\n",
        "#     # Combine masks\n",
        "#     combined_mask = cv.bitwise_and(global_mask, local_thresh_saturation)\n",
        "\n",
        "#     # Apply the combined mask\n",
        "#     segmented_hsv = cv.bitwise_and(hsv_img, hsv_img, mask=combined_mask)\n",
        "\n",
        "#     # Identify clusters: Apples (red hues) and Oranges (orange hues)\n",
        "#     apple_lower = np.array([0, 30, 50])    \n",
        "#     apple_upper = np.array([14, 255, 255])\n",
        "#     orange_lower = np.array([14, 30, 50])\n",
        "#     orange_upper = np.array([24, 255, 255])\n",
        "\n",
        "#     apple_mask = cv.inRange(segmented_hsv, apple_lower, apple_upper)\n",
        "#     orange_mask = cv.inRange(segmented_hsv, orange_lower, orange_upper)\n",
        "\n",
        "#     # Create magenta (apples) and blue (oranges) in BGR\n",
        "#     magenta = np.array([255, 0, 255], dtype=np.uint8)\n",
        "#     blue = np.array([255, 0, 0], dtype=np.uint8)\n",
        "\n",
        "#     # Initialize result\n",
        "#     result = img_read.copy()\n",
        "\n",
        "#     # Apply colors\n",
        "#     result[apple_mask > 0] = magenta\n",
        "#     result[orange_mask > 0] = blue\n",
        "\n",
        "#     # Create blur mask (areas not identified as apple or orange)\n",
        "#     blur_mask = cv.bitwise_not(cv.bitwise_or(apple_mask, orange_mask))\n",
        "\n",
        "#     # Apply blur to remaining regions\n",
        "#     blur = cv.GaussianBlur(img_read, (31, 31), 0)\n",
        "#     result[blur_mask > 0] = blur[blur_mask > 0]\n",
        "\n",
        "#     return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "from scipy.cluster.hierarchy import linkage, fcluster\n",
        "from scipy.spatial.distance import pdist\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "\n",
        "def AorO2(img_path, downscale_factor=4):\n",
        "    \"\"\"\n",
        "    Updated AorO2 using hierarchical clustering with downsampling to identify apples, oranges, and the background.\n",
        "    \"\"\"\n",
        "    # Load the image\n",
        "    img_read = cv.imread(img_path)\n",
        "    if img_read is None:\n",
        "        raise ValueError(f\"Image at path '{img_path}' could not be loaded.\")\n",
        "\n",
        "    # Downsample the image\n",
        "    img_small = cv.resize(img_read, \n",
        "                          (img_read.shape[1] // downscale_factor, img_read.shape[0] // downscale_factor),\n",
        "                          interpolation=cv.INTER_LINEAR)\n",
        "    \n",
        "    # Convert to HSV color space\n",
        "    hsv_small = cv.cvtColor(img_small, cv.COLOR_BGR2HSV)\n",
        "    h, w, _ = hsv_small.shape\n",
        "\n",
        "    # Flatten the image for clustering\n",
        "    flat_hsv = hsv_small.reshape((-1, 3))\n",
        "\n",
        "    # Compute pairwise distances and perform hierarchical clustering\n",
        "    pairwise_distances = pdist(flat_hsv, metric='euclidean')  # Calculate Euclidean distances\n",
        "    Z = linkage(pairwise_distances, method='ward')  # Perform Ward's hierarchical clustering\n",
        "\n",
        "    # Determine the cluster labels (3 clusters for apples, oranges, and others)\n",
        "    num_clusters = 3\n",
        "    labels = fcluster(Z, num_clusters, criterion='maxclust')\n",
        "\n",
        "    # Reshape labels to the downsampled image dimensions\n",
        "    cluster_map_small = labels.reshape((h, w))\n",
        "\n",
        "    # Upscale the cluster map back to the original image size\n",
        "    cluster_map = cv.resize(cluster_map_small, \n",
        "                             (img_read.shape[1], img_read.shape[0]), \n",
        "                             interpolation=cv.INTER_NEAREST)\n",
        "\n",
        "    # Assign clusters to apples, oranges, and others\n",
        "    apple_cluster = 1  # Adjust this based on visual inspection or automated heuristics\n",
        "    orange_cluster = 2  # Adjust this based on visual inspection or automated heuristics\n",
        "\n",
        "    apple_mask = (cluster_map == apple_cluster).astype(np.uint8) * 255\n",
        "    orange_mask = (cluster_map == orange_cluster).astype(np.uint8) * 255\n",
        "\n",
        "    # Create magenta (apples) and blue (oranges) in BGR\n",
        "    magenta = np.array([255, 0, 255], dtype=np.uint8)\n",
        "    blue = np.array([255, 0, 0], dtype=np.uint8)\n",
        "\n",
        "    # Initialize result\n",
        "    result = img_read.copy()\n",
        "\n",
        "    # Apply colors\n",
        "    result[apple_mask > 0] = magenta\n",
        "    result[orange_mask > 0] = blue\n",
        "\n",
        "    # Create blur mask (areas not identified as apple or orange)\n",
        "    blur_mask = cv.bitwise_not(cv.bitwise_or(apple_mask, orange_mask))\n",
        "\n",
        "    # Apply blur to remaining regions\n",
        "    blur = cv.GaussianBlur(img_read, (31, 31), 0)\n",
        "    result[blur_mask > 0] = blur[blur_mask > 0]\n",
        "\n",
        "    return result\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "result_image = AorO2(\"AppleOrange/AorO6.jpg\", downscale_factor=4)\n",
        "result_imageS = cv.resize(result_image, (960, 540))\n",
        "cv.imwrite(\"segmented_image.jpg\", result_image)\n",
        "cv.imshow(\"Result\", result_imageS)\n",
        "cv.waitKey(0)\n",
        "cv.destroyAllWindows()\n",
        "\n",
        "# # Visualize the clusters\n",
        "# plt.imshow(cluster_map, cmap='viridis')\n",
        "# plt.title(\"Cluster Map\")\n",
        "# plt.colorbar()\n",
        "# plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0fT5O_lDVvy"
      },
      "source": [
        "# My test will be performed below\n",
        "Using my own code either at the end of this file or separately on my computer, I will just call the  ```AorO()``` or ```AorO2() functions in different ways and enjoy the outcomes :)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
